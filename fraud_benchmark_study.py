# -*- coding: utf-8 -*-
"""fraud_benchmark_study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13VuPWLUqFMUdbkqaJ6U3QaAWj8-kCU-u

**Import Libraries and Load Data**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.neighbors import LocalOutlierFactor
from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix

try:
    data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
    print("Dataset loaded successfully!")
except FileNotFoundError:
    print("Error: File not found. Please check the path.")

"""**Data Preparation**"""

# Define X (Features) and Y (Target)
columns = [c for c in data.columns if c not in ["Class"]]
X = data[columns]
Y = data["Class"]

# Split data: 80% Train, 20% Test
# We use random_state=42 for reproducibility
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Calculate Outlier Fraction (needed for Anomaly Detection models)
fraud_cases = len(Y[Y == 1])
valid_cases = len(Y[Y == 0])
outlier_fraction = fraud_cases / valid_cases

print(f"Test Set Shape: {X_test.shape}")
print(f"Fraud Ratio (Outlier Fraction): {outlier_fraction:.5f}")

"""**Model 1 - Isolation Forest (Unsupervised)**"""

print("Running Isolation Forest...")

# Initialize Model
# We fit the model on X_test directly to find anomalies in the test set
iso_forest = IsolationForest(n_estimators=100,
                             max_samples=len(X_test),
                             contamination=outlier_fraction,
                             random_state=42,
                             n_jobs=-1)

iso_forest.fit(X_test)
y_pred_iso = iso_forest.predict(X_test)

# Map predictions: 1 -> 0 (Normal), -1 -> 1 (Fraud)
y_pred_iso[y_pred_iso == 1] = 0
y_pred_iso[y_pred_iso == -1] = 1

print("Isolation Forest Completed.")

"""**Model 2 - Local Outlier Factor (Unsupervised)**"""

print("Running Local Outlier Factor (LOF)...")

# Taking a smaller sample from X_test to speed up LOF (Computationally expensive)
# Using only 10% of the test set for LOF
X_test_lof = X_test.iloc[:5000]
y_test_lof = y_test.iloc[:5000]

lof = LocalOutlierFactor(n_neighbors=20,
                         algorithm='auto',
                         contamination=outlier_fraction)

# Fit and Predict
y_pred_lof = lof.fit_predict(X_test_lof)

# Map predictions: 1 -> 0 (Normal), -1 -> 1 (Fraud)
y_pred_lof[y_pred_lof == 1] = 0
y_pred_lof[y_pred_lof == -1] = 1

print("LOF Completed.")

"""**Model 3 - Random Forest (Supervised)**"""

print("Training Random Forest Classifier...")

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)

# Train on Training Data
rf_model.fit(X_train, y_train)

# Predict on Test Data
y_pred_rf = rf_model.predict(X_test)

print("Random Forest Completed.")

"""**Model 4 - LIGHTGBM (Supervised - Gradient Boosting)**"""

from lightgbm import LGBMClassifier

print("Training LightGBM Classifier (with is_unbalance=True)...")

# is_unbalance=True: Modele verinin dengesiz olduğunu ve azınlık sınıfına (Fraud)
# öncelik vermesi gerektiğini söyleriz.
lgbm_model = LGBMClassifier(n_estimators=100,
                            is_unbalance=True,  # <-- SİHİRLİ DOKUNUŞ BURADA!
                            random_state=42,
                            n_jobs=-1,
                            verbose=-1)

# Eğit
lgbm_model.fit(X_train, y_train)

# Test Et
y_pred_lgbm = lgbm_model.predict(X_test)

print("LightGBM Tuned Completed.")

"""**Model 5 - SMOTE + Random Forest**"""

from imblearn.over_sampling import SMOTE

print("Applying SMOTE to generate synthetic fraud data...")

# 1. Initialize SMOTE
smote = SMOTE(random_state=42)

# 2. Apply SMOTE to Training Data ONLY
# CRITICAL: Never apply SMOTE to Test data, it causes data leakage!
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Display class distribution before and after
print(f"Original Training Shape: {y_train.value_counts()}")
print(f"Resampled (SMOTE) Training Shape: {y_train_smote.value_counts()}")
# Now Fraud (1) and Normal (0) counts should be equal in the training set

print("\nTraining Random Forest on SMOTE data...")
# We use a standard Random Forest (no need for class_weight adjustments here)
rf_smote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)

# Fit on the SMOTE-augmented training data
rf_smote.fit(X_train_smote, y_train_smote)

# Predict on the original Test data
y_pred_smote = rf_smote.predict(X_test)

print("SMOTE + Random Forest Completed.")

"""**GRAND BENCHMARK - COMPARISON & VISUALIZATION**"""

results = {
    'Model': ['Isolation Forest', 'LOF', 'Random Forest', 'LightGBM (Tuned)', 'RF + SMOTE'],

    'Accuracy': [
        accuracy_score(y_test, y_pred_iso),
        accuracy_score(y_test_lof, y_pred_lof),
        accuracy_score(y_test, y_pred_rf),
        accuracy_score(y_test, y_pred_lgbm),
        accuracy_score(y_test, y_pred_smote) # New Contender
    ],

    'Recall (Fraud Capture)': [
        recall_score(y_test, y_pred_iso),
        recall_score(y_test_lof, y_pred_lof),
        recall_score(y_test, y_pred_rf),
        recall_score(y_test, y_pred_lgbm),
        recall_score(y_test, y_pred_smote) # New Contender
    ],

    'Precision': [
        precision_score(y_test, y_pred_iso),
        precision_score(y_test_lof, y_pred_lof),
        precision_score(y_test, y_pred_rf),
        precision_score(y_test, y_pred_lgbm),
        precision_score(y_test, y_pred_smote) # New Contender
    ]
}

df_results = pd.DataFrame(results)

# --- VISUALIZATION ---
plt.figure(figsize=(15, 6))

# Plot 1: Recall
plt.subplot(1, 2, 1)
ax1 = sns.barplot(x='Model', y='Recall (Fraud Capture)', data=df_results, palette='viridis')
plt.title('Fraud Capture Rate (Recall)\n(Higher is Better)', fontsize=14)
plt.ylim(0, 1.1)
plt.xticks(rotation=15)
for index, row in df_results.iterrows():
    ax1.text(index, row['Recall (Fraud Capture)'] + 0.02,
             f"{row['Recall (Fraud Capture)']:.2f}", ha='center', fontweight='bold')

# Plot 2: Accuracy
plt.subplot(1, 2, 2)
sns.barplot(x='Model', y='Accuracy', data=df_results, palette='magma')
plt.title('Overall Accuracy', fontsize=14)
plt.ylim(0.90, 1.005)
plt.xticks(rotation=15)
for index, row in df_results.iterrows():
    plt.text(index, row['Accuracy'] + 0.002,
             f"{row['Accuracy']:.3f}", ha='center', fontweight='bold')

plt.tight_layout()
plt.show()

print("\n--- ULTIMATE BENCHMARK TABLE ---")
print(df_results)

